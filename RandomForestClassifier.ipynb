{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(r'C:\\Users\\luqqa\\OneDrive\\Escritorio\\DiploDatos\\Practico AS\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clasificacionDias(dia):\n",
    "    if dia in ['Monday','Tuesday','Wednesday','Thursday']:\n",
    "        return 'low day'\n",
    "    if dia in ['Friday']:\n",
    "        return 'party'\n",
    "    else:\n",
    "        return'weekend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "\n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # the next three operations are the ones we have just presented in the previous lines\n",
    "    #df.drop_duplicates(keep='first', ignore_index=True, inplace=True)\n",
    "\n",
    "    # drop the columns we won't use (it may be good to use them somehow)\n",
    "    #df = df.drop([\"Upc\"], axis=1)\n",
    "    mask = df.Upc.isna()\n",
    "    column_name = 'Upc'\n",
    "    df.loc[mask, column_name] = 0\n",
    "\n",
    "    #Reemplazamos nulos en FinelineNumber\n",
    "    mask = (df.FinelineNumber.isna())&(df.DepartmentDescription=='PHARMACY RX')\n",
    "    column_name = 'FinelineNumber'\n",
    "    df.loc[mask, column_name] = 4822.0\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "\n",
    "    # now we add the groupby values\n",
    "    #df = df.groupby([\"VisitNumber\", \"Weekday\",\"FinelineNumber\"], as_index=False).sum()\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "\n",
    "    df['Segmentacion Semana']=df.Weekday.apply(lambda x:clasificacionDias(x))\n",
    "    df = pd.get_dummies(df, columns=[\"Segmentacion Semana\"], dummy_na=True)\n",
    "\n",
    "    # finally, we do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "\n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(r'C:\\Users\\luqqa\\OneDrive\\Escritorio\\DiploDatos\\Practico AS\\train - copia.csv',r'C:\\Users\\luqqa\\OneDrive\\Escritorio\\DiploDatos\\Practico AS\\test - copia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67029, 85)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import ensemble \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'random_state'      : [2],\n",
    "    'max_features': ['auto'],\n",
    "    \"n_estimators\": [50, 100, 150]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=150, random_state=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "RFT = GridSearchCV(ensemble.RandomForestClassifier(),param_grid, cv=3, scoring='accuracy')\n",
    "RFT.fit(X_train, y_train);\n",
    "best_tree_RFT = RFT.best_estimator_\n",
    "best_tree_RFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe is used to store the computed results\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.6881074168797955\n",
      "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'max_features': ['auto'],\n",
      "                         'n_estimators': [50, 100, 150], 'random_state': [2]},\n",
      "             scoring='accuracy')\n",
      "The best classifier so far is: \n",
      "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'max_features': ['auto'],\n",
      "                         'n_estimators': [50, 100, 150], 'random_state': [2]},\n",
      "             scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print('Best Decision Tree accuracy: ', RFT.best_score_)\n",
    "print(RFT)\n",
    "results = results.append({'clf': RFT, 'best_acc': RFT.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = RFT.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r\"C:\\Users\\luqqa\\OneDrive\\Escritorio\\DiploDatos\\Practico AS\\submissionRandomForestClassifier.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
